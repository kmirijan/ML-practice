summary(fit.Y)
fit.X=lm(x~y+0)
summary(fit.X)
x = 1:100
y = 100:1
fit.Y = lm(y~x+0) #lm without intercept
summary(fit.Y)
fit.X=lm(x~y+0)
summary(fit.X)
### Q13
### Q13
x = rnorm(100)
eps = rnorm(100, sd=sqrt(.25))
y = -1 + .5*x + eps
length(y)
plot(x,y)
plot(x,y)
fit.13.1 = lm(y~x)
summary(fit.13.1)
abline(fit.13.1, col='2')
abline(-1, 0.5, col='1')
abline(-1, 0.5, col='3')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
eps = rnorm(100, sd=sqrt(.1))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.1 = lm(y~x)
summary(fit.13.1)
abline(-1, 0.5, col='3')
abline(fit.13.1, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
### Q13
x = rnorm(100)
eps = rnorm(100, sd=sqrt(.25))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.1 = lm(y~x)
summary(fit.13.1)
abline(-1, 0.5, col='3')
abline(fit.13.1, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
eps = rnorm(100, sd=sqrt(.1))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.2 = lm(y~x)
summary(fit.13.1)
abline(-1, 0.5, col='3')
abline(fit.13.1, col='2')
fit.13.2 = lm(y~x)
summary(fit.13.2)
abline(fit.13.2, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
### Q13
x = rnorm(100)
eps = rnorm(100, sd=sqrt(.25))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.1 = lm(y~x)
summary(fit.13.1)
abline(-1, 0.5, col='3')
abline(fit.13.1, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
eps = rnorm(100, sd=sqrt(.1))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.2 = lm(y~x)
summary(fit.13.2)
abline(-1, 0.5, col='3')
abline(fit.13.2, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
eps = rnorm(100, sd=sqrt(.5))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.3 = lm(y~x)
summary(fit.13.2)
abline(-1, 0.5, col='3')
abline(fit.13.2, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
eps = rnorm(100, sd=sqrt(.5))
y = -1 + .5*x + eps
length(y)
plot(x,y)
fit.13.3 = lm(y~x)
summary(fit.13.3)
abline(-1, 0.5, col='3')
abline(fit.13.3, col='2')
legend("topleft", c("Least square", "Regression"), col = c("3", "2"), lty = c(1, 1))
confint(fit.13.1)
confint(fit.13.2)
confint(fit.13.3)
### Q14: How collinearity effects your system
set.seed(1)
x1=runif(100)
x2=.5*x1+rnorm(100)/10
y = 2+2*x1+0.3*x2+rnomr(100)
y = 2+2*x1+0.3*x2+rnorm(100)
plot(x1, x2)
cor(x1, x2)
fit.14.1 = lm(y~x1+x2)
summary(fit.14.1)
fit.14.2 = lm(y~x1)
summary(fit.14.2)
fit.14.3 = lm(y~x2)
summary(fit.14.3)
x1=c(x1, .1)
x2=c(x2, .8)
y=c(y,6)
fit.14.4 = lm(y~x1+x2)
summary(fit.14.4)
fit.14.6 = lm(y~x1)
summary(fit.14.6)
fit.14.7 = lm(y~x2)
summary(fit.14.7)
plot(fit.14.4)
par(mfrow=c(2,2))
plot(fit.14.4)
plot(fit.14.6)
plot(fit.14.7)
### Q15
names(Boston)
fit.zn = lm(crim~zn, Boston)
fit.rm = lm(crim~rm, Boston)
fit.zn = lm(crim~zn, Boston)
fit.indus = lm(crim~indus, Boston)
fit.chas = lm(crim~chas, Boston)
fit.nox = lm(crim~nox, Boston)
fit.rm = lm(crim~rm, Boston)
fit.age = lm(crim~age, Boston)
fit.dis = lm(crim~dis, Boston)
fit.rad = lm(crim~rad, Boston)
fit.tax = lm(crim~tax, Boston)
fit.black = lm(crim~black, Boston)
fit.lstat = lm(crim~lstat, Boston)
fit.medv = lm(crim~medv, Boston)
summary(fit.zn)
plot(crim, zn)
plot(zn, crime)
plot(zn, crim)
abline(fit.zn, col=2)
summary(fit.indus)
plot(indus, crim)
abline(fit.indus, col=2)
abline(fit.chas, col=2)
summary(fit.chas)
plot(chas, crim)
abline(fit.chas, col=2)
summary(fit.nox)
plot(nox, crim)
abline(fit.nox, col=2)
summary(fit.rm)
plot(rm, crim)
abline(fit.rm, col=2)
summary(fit.age)
plot(age, crim)
abline(fit.age, col=2)
summary(fit.dis)
plot(dis, crim)
abline(fit.dis, col=2)
summary(fit.rad)
plot(rad, crim)
abline(fit.rad, col=2)
summary(fit.tax)
plot(tax, crim)
abline(fit.tax, col=2)
summary(fit.black)
plot(black, crim)
abline(fit.black, col=2)
summary(fit.lstat)
plot(lstat, crim)
abline(fit.lstat, col=2)
summary(fit.medv)
plot(medv, crim)
abline(fit.medv, col=2)
fit.all = lm(crim~., Boston)
summary(fit.all)
simple.reg <- vector("numeric",0)
simple.reg <- c(simple.reg, fit.zn$coefficient[2])
simple.reg <- c(simple.reg, fit.indus$coefficient[2])
simple.reg <- c(simple.reg, fit.chas$coefficient[2])
simple.reg <- c(simple.reg, fit.nox$coefficient[2])
simple.reg <- c(simple.reg, fit.rm$coefficient[2])
simple.reg <- c(simple.reg, fit.age$coefficient[2])
simple.reg <- c(simple.reg, fit.dis$coefficient[2])
simple.reg <- c(simple.reg, fit.rad$coefficient[2])
simple.reg <- c(simple.reg, fit.tax$coefficient[2])
simple.reg <- c(simple.reg, fit.ptratio$coefficient[2])
simple.reg <- c(simple.reg, fit.black$coefficient[2])
simple.reg <- c(simple.reg, fit.lstat$coefficient[2])
simple.reg <- c(simple.reg, fit.medv$coefficient[2])
fit.ptratio = lm(crim~ptratio, Boston)
summary(fit.ptratio)
plot(ptratio, crim)
abline(fit.ptratio, col=2)
simple.reg <- vector("numeric",0)
simple.reg <- c(simple.reg, fit.zn$coefficient[2])
simple.reg <- c(simple.reg, fit.indus$coefficient[2])
simple.reg <- c(simple.reg, fit.chas$coefficient[2])
simple.reg <- c(simple.reg, fit.nox$coefficient[2])
simple.reg <- c(simple.reg, fit.rm$coefficient[2])
simple.reg <- c(simple.reg, fit.age$coefficient[2])
simple.reg <- c(simple.reg, fit.dis$coefficient[2])
simple.reg <- c(simple.reg, fit.rad$coefficient[2])
simple.reg <- c(simple.reg, fit.tax$coefficient[2])
simple.reg <- c(simple.reg, fit.ptratio$coefficient[2])
simple.reg <- c(simple.reg, fit.black$coefficient[2])
simple.reg <- c(simple.reg, fit.lstat$coefficient[2])
simple.reg <- c(simple.reg, fit.medv$coefficient[2])
mult.reg <- vector("numeric", 0)
mult.reg <- c(mult.reg, fit.all$coefficients)
mult.reg <- mult.reg[-1]
plot(simple.reg, mult.reg, col = "red")
fit.zn2 <- lm(crim ~ poly(zn, 3))
summary(fit.zn2)
names(Boston)
fit.indus2 <- lm(crim ~ poly(indus, 3))
fit.chas2 <- lm(crim ~ poly(chas, 3))
# fit.chas2 <- lm(crim ~ poly(chas, 3)) Can't do this
fit.nox2 <- lm(crim ~ poly(nox, 3))
fit.rm2 <- lm(crim ~ poly(rm, 3))
fit.age2 <- lm(crim ~ poly(age, 3))
fit.dis2 <- lm(crim ~ poly(dis, 3))
fit.rad2 <- lm(crim ~ poly(rad, 3))
fit.tax2 <- lm(crim ~ poly(tax, 3))
fit.ptratio2 <- lm(crim ~ poly(ptratio, 3))
fit.black2 <- lm(crim ~ poly(black, 3))
fit.lstat2 <- lm(crim ~ poly(lstat, 3))
fit.medv2 <- lm(crim ~ poly(medv, 3))
summary(fit.zn2)
summary(fit.indus2)
summary(fit.nox2)
summary(fit.rm2)
summary(fit.age2) #
summary(fit.dis2)
summary(fit.rad2)
summary(fit.tax2)
summary(fit.ptratio2)
summary(fit.black2) #
summary(fit.lstat2)
summary(fit.medv2)
?glm
require(ISLR)
names(Smarket)
summary(Smarket)
?Smarket
pairs(Smarket, col=Smarket$Direction)
attach(SSmarket)
attach(Smarket)
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family = binomial)
summary(glm.fit)
glm.probs=predict(glm.fit, type = 'response')
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5, "Up", 'Down')
table(glm.pred, Direction)
mean(glm.pred==Direction)
train=Year<2005
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family = binomial, subset=train)
glm.probs(glm.fit, newdata=Smarket[!train], type='response')
glm.probs=predict(glm.fit, newdata=Smarket[!train], type='response')
train=Year<2005
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family = binomial, subset=train)
glm.probs=predict(glm.fit, newdata=Smarket[!train], type='response')
glm.probs=predict(glm.fit, newdata=Smarket[!train,], type='response')
glm.predict=ifelse(glm.probs>0.5, 'Up', 'Down')
Direction.2005=Smarket$Direction[!train]
table(glm.pred, Direction.2005)
table(glm.pred, Direction.2005)
train=Year<2005
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family = binomial, subset=train)
glm.probs=predict(glm.fit, newdata=Smarket[!train,], type="response")
Direction.2005=Smarket$Direction[!train]
glm.predict=ifelse(glm.probs>0.5, 'Up', 'Down')
Direction.2005=Smarket$Direction[!train]
glm.pred=ifelse(glm.probs>0.5, 'Up', 'Down')
Direction.2005=Smarket$Direction[!train]
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
glm.fit = glm(Direction~Lag1+Lag2, data=Smarket, family = binomial, subset=train)
glm.probs=predict(glm.fit, newdata=Smarket[!train,], type="response")
glm.pred=ifelse(glm.probs>0.5, 'Up', 'Down')
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
summary(glm.fit)
require(ISLR)
require(MASS)
lda.fit=lda(Direction~Lag1+Lag2, data=Smarket, subset=Year<2005)
lda.fit
summary(lda.fit)
lda.fit
plot(lda.fit)
Smarket.2005=subset(Smarket, Year==2005)
lda.pred = predict(lda.fit, Smarket.2005)
lda.pred[1:5,]
class(lda.pred)
data.frame(lda.pred)[1:5,]
table(lda.pred$class, Smarket.2005$Direction)
mean(lda.pred$class==Smarket.2005$Direction)
library(class)
?knn
ls()
attach(Smarket)
detach(Smarket.2005)
detach(Smarket)
ls()
attach(Smarket)
object(8)
objects(8)
objects(7)
Xlag=cbind(Lag1,Lag2)
Xlag[1:5]
Xlag[1:5,]
train=Year<2005
knn.pred=knn(Xlag[train,], Xlag[!train,], Direction[train,], k=1)
knn.pred=knn(Xlag[train,], Xlag[!train,], Direction[train], k=1)
table(knn.pred, Direction[!train])
mean(knn.pred==Direction[!train])
knn.pred=knn(Xlag[train,], Xlag[!train,], Direction[train], k=5)
table(knn.pred, Direction[!train])
mean(knn.pred==Direction[!train])
knn.pred=knn(Xlag[train,], Xlag[!train,], Direction[train], k=10)
table(knn.pred, Direction[!train])
mean(knn.pred==Direction[!train])
library(ISLR)
names(Smarket)
summary(Smarket)
pairs(Smarket)
cor(Smarket)
Smarket[,-9]
Smarket[1:5,-1]
Smarket[1:5,-2]
Smarket[1:5,-9]
cor(Smarket[,-9])
cor(Smarket[,-9]) > .2
cor(Smarket[,-9]) > abs(.5)
cor(Smarket[,-9]) > abs(.6)
plot(Volume)
plot(Volume, Year)
plot(Year, Volume)
### 4.6.2
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, family=binomial, data=Smarket)
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
summary(glm.fit)$coef[,4]
glm.prob = predict(glm.fit, type = 'response') # response outputs probability of the form P(Y=1 | X)
glm.prob[1:10]
contrasts(Direction)
glm.pred=rep("Down", 1250)
?rep()
glm.rep
glm.pred
glm.pred[glm.prob>.5]="Up"
table(glm.pred, Direction)
mean(glm.pred==Direction)
train=(Year<2005)
dim(Smarket.2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
dim(Smarket)
dim(Smarket[train])
dim(Smarket[train,])
Direction.2005=Direction[!train]
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, family=binomial, data=Smarket, subset=train)
summary(glm.fit)
glm.prob=predict(glm.fit, Smarket.2005, type='response')
glm.pred[glm.prob>.5, 'Up']
glm.pred[glm.prob>.5]="Up"
table(glm.pred, Direction.2005)
Direction.2005=Direction[!train]
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, family=binomial, data=Smarket, subset=train) #Make model on training set
summary(glm.fit)
glm.prob=predict(glm.fit, Smarket.2005, type='response') #Predict on !train set
glm.pred=rep("Down", 252)
glm.pred[glm.prob>.5]="Up"
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
#Make model on training set using less predictors
glm.fit = glm(Direction~Lag1+Lag2, family=binomial, data=Smarket, subset=train)
summary(glm.fit)
glm.prob=predict(glm.fit, Smarket.2005, type='response') #Predict on !train set
glm.pred=rep("Down", 252)
glm.pred[glm.prob>.5]="Up"
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
predict(glm.fit, newdata=data.frame(Lag1=c(1.2,1.5), Lag2=c(1.1, -0.8)), "response")
#4.6.3
library(MASS)
lda.fit=lda(Direction~Lag1+Lag2, data = Smarket, subset=train)
lda.fit
plot(lda.fit)
lda.pred=predict(lda.fit, Smarket.2005)
names(lda.pred)
x(lda.pred)
lda.pred$x
lda.pred$class
lda.pred$posterior
lda.class=lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class==Direction.2005)
lda.pred$posterior
lda.pred$posterior[,1]>=.5
lda.pred$posterior[,0]>=.5
lda.pred$posterior[,1]>=.5
lda.pred$posterior[,2]>=.5
lda.pred$posterior[,1]>=.5
sum(lda.pred$posterior[,1]>=.5)
sum(lda.pred$posterior[,1]<.5) # How many Down Prediction <.5
lda.pred$posterior[1:20,1]
lda.class[1:20]
sum(lda.pred$posterior[,1]>=.9) # How many Down predictions >=.5
#4.6.4
qda.fit=qda(Direction~Lag1+Lag2, data=Smarket, subset=train)
qda.fit
qda.pred = predict(qda.fit, Smarket.2005)
qda.pred$class
qda.class=qda.pred$class
table(qda.class, Direction.2005)
mean(qda.class==Direction.2005)
#4.6.5
library(class)
train.X=cbind(Lag1, Lag2)[train,] # Binds the Lag1 and Lag2 vectors where train==TRUE into a single matrix
test.X=cbind(Lag1, Lag2)[!train,]
train.Direction = Direction[train]
set.seed(1)
set.seed(1) #In knn ties, R will randomly break the tie. Set a seed to ensure reproduibility
knn.pred=knn(train.X, test.X, train.Direction, k=1)
table(knn.pred, Direction.2005)
mean(knn.pred==Direction.2005)
knn.pred=knn(train.X, test.X, train.Direction, k=3)
table(knn.pred, Direction.2005)
mean(knn.pred==Direction.2005)
#4.6.6
dim(Caravan)
attach(Caravan)
?Caravan
summary(Caravan)
summary(Purchase)
stanardized.X=scale(Caravan[,-86]) # Scale all predictor variables
var(Caravan[,1])
var(Caravan[,2])
?var()
var.(stanardized.X[,1])
var(stanardized.X[,1])
var(stanardized.X[,2])
standardized.X
standardized.X=scale(Caravan[,-86]) # Scale all predictor variables
var(Caravan[,1]) # Variance of variable 1
var(Caravan[,2])
?var()
var(standardized.X[,2])
var(standardized.X[,1])
var(standardized.X[,2])
standardized.X
test = 1:1000
train.X=standardized.X[-test]
test.X=standardized.X[test]
train.X=standardized.X[-test,]
test.X=standardized.X[test,]
train.Y=Purchase[-test]
test.Y=Purchase[test]
set.seed(1)
?knn
knn.pred=knn(train.X, test.X, train,Y, k=1)
knn.pred=knn(train.X, test.X, train.Y, k=1)
mean(test.Y!=knn.pred)
mean(test.Y!="No")
table(knn.pred, test.Y)
# With K=3
knn.pred=knn(train.X, test.X, train.Y, k=1)
mean(test.Y!=knn.pred) #Our prediction error rate
mean(test.Y!="No") # Binary Classification of always saying No
table(knn.pred, test.Y)
9/77
# With K=3
knn.pred=knn(train.X, test.X, train.Y, k=3)
mean(test.Y!=knn.pred) #Our prediction error rate
mean(test.Y!="No") # Binary Classification of always saying No
table(knn.pred, test.Y)
# With K=5
knn.pred=knn(train.X, test.X, train.Y, k=5)
mean(test.Y!=knn.pred) #Our prediction error rate
mean(test.Y!="No") # Binary Classification of always saying No
table(knn.pred, test.Y)
# Check against logistic regression
glm.fit=glm(Purchase~., Caravan, family = binomial, subset=-test)
glm.prob=predict(glm.fit, Caravan[test,], type = 'response')
glm.pred=rep("No", 1000)
glm.pred[glm.prob>.5]="Yes"
table(glm.pred, test.Y)
glm.pred[glm.prob>.25]='Yes'
table(glm.pred, test.Y)
library(ISLR)
dim(Weekly)
names(Weekly)
summary(Weekly)
cor(Weekly)
cor(Weekly[, :-9])
cor(Weekly[,-9])
cor(Weekly[,-9]) > .6
pairs(Weekly)
pairs(Weekly, col="binomial")
pairs(Weekly, col=Direction)
attach(Weekly)
detach(Smarket)
attach(Weekly)
